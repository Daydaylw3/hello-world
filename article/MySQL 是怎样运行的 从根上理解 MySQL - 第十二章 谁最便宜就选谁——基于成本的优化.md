[toc]

------

## 12.1 什么是成本

我们之前老说MySQL在执行一个查询时可以有不同的执行方案.它会选择其中成本最低，或者说代价最低的那种方案去真正地执行查询。不过我们之前对成本的描述是非常模糊的，其实一条查询语句在MySQL 中的执行成本是由两个方面组成的

+ `I/O` 成本：
+ CPU 成本：读取记录以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间称为CPU 成本

MySQL 规定：读取一个页面花费的成本默认为 1.0；读取以及检测一条记录是否符合搜索条件的成本默认是 0.2。1.0、0.2 这些数字称为**成本常数**

> 在读取记录时，即使不需要检测记录是否符合搜索条件，其成本也算作 0.2

## 12.2 单表查询的成本

### 12.2.1 准备工作

single_table

### 12.2.2 基于成本的优化步骤

在真正执行一条单表查询语句之前， MySQL 的优化器会找出所有可以用来执行该语句的方案，并在对比这些方案之后找出成本最低的方案。

这个成本最低的方案就是所谓的**执行计划**

1. 根据搜索条件， 找出所有可能使用的索引
2. 计算全表扫描的代价
3. 计算使用不同索引执行查询的代价
4. 对比各种执行方案的代价，找出成本最低的那个方案

```mysql
select * from single_table where
	key1 in ('a', 'b', 'c') and
	key2 > 10 and key2 < 1000 and
	key3 > key2 and
	key_part1 like '%hello%' and
	common_field = '123';
```

#### 1. 根据搜索条件，找出所有可能使用的索引

MySQL 把一个查询中可能使用到的索引称之为 possible keys

涉及的几个搜索条件

+ key1 in ('a', 'b', 'c')：二级索引 idx_key1
+ key2 > 10 and key2 < 1000：二级索引 uk_key2
+ key3 > key2：由于没有与常数进行比较， 因此不能产生合适的扫描区间
+ key_part1 like '%hello%'：通过 LIKE 操作符与以通配符开头的字符串进行比较，不能产生合适的扫描区间
+ common_field = '123'：没有建立索引

> possible keys 有 idx_key1 和 uk_key2

#### 2. 计算全表扫描的代价

需要将聚簇索引对应的页面加载到内存中，然后再检测记录是否符合搜索条件。

由于查询成本 = I/O 成本 + CPU 成本

+ 聚簇索引占用的页面数
+ 该表中的记录数

这两个信息从哪里来呢？**MySQL 为每张表维护了一系列的统计信息**。

```mysql
show table status;
```

```mysql
mysql> show table status like 'single_table'\G;
*************************** 1. row ***************************
           Name: single_table
         Engine: InnoDB
        Version: 10
     Row_format: Dynamic
           Rows: 0
 Avg_row_length: 0
    Data_length: 16384
Max_data_length: 0
   Index_length: 65536
      Data_free: 0
 Auto_increment: 1
    Create_time: 2022-05-11 22:59:42
    Update_time: NULL
     Check_time: NULL
      Collation: utf8_general_ci
       Checksum: NULL
 Create_options: 
        Comment: 
1 row in set (0.00 sec)
```

目前只关心两个选项

+ Rows：表示表中的记录条数。对于使用 MylSAM 存储引擎的表来说，该值是准确的；对于使用 InnoDB 存储引擎的表来说，该值是一个估计值。
+ Data_length：表示表占用的存储空间字节数。对于使用 MylSAM 存储引擎的表来说，该值就是数据文件的大小；对于使用 InnoDB 存储引擎的表来说，该值就相当于聚簇索引占用的存储空间大小。（Data_length = 聚簇索引的页面数量 × 每个页面的大小）

single_table 表使用默认的 16KB 页面大小，可以反向推导出聚簇索引的页面数量

+ I/O 成本：97 × 1.0 + 1.1 = 98.1；97 是聚簇索引占用的页面数量，1.0 是加载一个页面的成本常数，1.1 是一个微调值
+ CPU 成本：9693 × 0.2 + 1.0 = 1939.6；9693 指的是统计数据中表的记录数，0.2 是访问一条记录所需的成本常数，1.0 是一个微调值
+ 总成本 98.1 + 1939.6 = 2037.7

#### 3. 计算使用不同索引执行查询的代价

前述查询可能使用到  idx_key1 和 uk_key2 这两个索引，我们需要分析单独使用这些索引执行查询的成本，最后还要分析是否可能使用到索引合并。

MySQL 查询优化器先分析使用唯一二级索引的成本，再分析使用普通索引的成本

##### （1）使用 uk_key2 执行查询分析的成本

扫描区间是（10， 1000）；对于使用二级索引+回表方式执行的查询，MySQL 在计算这种查询的成本时，依赖于两方面的数据：扫描区间数量和需要回表的记录数

+ 扫描区间数量

  无论某个扫描区间的二级索引到底占用了多少页面，查询优化器粗暴地认为**读取索引的一个扫描区间的 l/O 成本与读取一个页面的 l/O 成本是相同的**。

  所以访问这个扫描区间的二级索引所付出的 I/O 成本是：1 × 1.0 = 1.0

+ 需要回表的记录数

  查询优化器需要计算二级索引的某个扫描区间到底包含多少条记录，对于本例来说就是要计算 uk_key2 在（10， 1000）扫描区间中包含多少二级索引记录

  + 先根据 key2> 10 条件访问 uk_key2 对应的B+ 树索引，找到满足key2> 10 条件的第一条记录（区间最左记录）。这个过程的性能消耗可以忽略不计

  + 然后再根据key2< 1 000 条件继续从uk_key2 对应的B+ 树索引中找出最后一条满足这个条件的记录（区间最右记录）。这个过程的性能消耗可以忽略不计

  + 如果区间最左记录和区间最右记录相隔不太远（MySQL 5.7.22 版本中只要相隔不超过 10 个页面），就可以精确统计出满足 key2 > 10 and key2 < 1000 条件的二级索引记录的条数

    > 数据页有一个Page Header 部分。Page Header 中有一个名为 PAGE_N_RECS 的属性，该属性代表了页面中目前有多少条记录。所以相隔不太远，可以直接遍历这些页面，计算 PAGE_N_RECS 的和

  + 否则只沿着区间最左记录向右读10 个页面，计算每个页面平均包含多少记录， 然后用这个平均值乘以区间最左记录和区间最右记录之间的页面数量。（如何估计区间最左记录和区间最右记录之间的页面数量？）

    + 递归找目录项记录页中包含最左记录页的目录项和最右记录页的目录项的页，计算两个页面目录项之间间隔的记录数
    
  
  假设根据上述方法测得（10， 1000）内有 95 条记录。读取这95 条二级索引记录需要付出的CPU 成本就是：95 × 0.2 + 0.01 = 19.01，0.01 是微调值
  
+ 根据这些记录的主键值到聚簇索引中执行回表操作

  MySQL 在评估回表操作的 I/O 成本时依旧很豪放：他们认为每次回表操作都相当于访问一个页面，也就是说二级索引扫锚区间中有多少记录，就需要进行多少次回表操作，也就是需要进行多少次页面 I/O。所以回表操作带来的 I/O 成本就是：95 × 1.0 = 95.0

+ 回表操作后得到完整的用户记录，然后再检测其他搜索条件是否成立

  95 × 0.2 = 19.0

所以本例中使用uk_key2 执行查询的成本就如下

+ I/O 成本：1.0 + 95.0 = 96.0
+ CPU 成本：19.01 + 19.0 = 38.01
+ 总成本：134.01

##### （2）使用 idx_key1 执行查询的成本分析

idx_keyl 对应的搜索条件是 key l lN ('a','b','c')，也就是说相当于3 个单点扫锚区间

+ ['a', 'a']
+ ['b', 'b']
+ ['c', 'c']

+ 扫描区间的数量：3 × 1.0 = 3.0
+ 需要回表的记录数，假设这 3 个单点扫描区间总共需要回表的记录数是 118，读取这些二级索引记录的 CPU 总成本是：118 × 0.2 + 0.01 = 23.61
+ 根据这些记录中的主键值到聚簇索引中执行回表操作：I/O 成本：118 × 1.0 = 118.0
+ 针对回表操作后读取到的完整用户记录，比较其他搜索条件是否成立。CPU 成本：118 × 0.2 = 23.6

使用 idx_key1 执行查询的成本就如下

+ I/O 成本：3.0 + 118.0 = 121.0
+ CPU 成本：23.61 + 23.6 = 47.21
+ 总成本：168.21

##### （3）是否有可能索引合并（Index Merge）

不会

#### 4. 对比各种执行方案的代价，找出成本最低的那个方案

+ 全表扫描：2037.7
+ uk_key2：134.01
+ idx_key1：168.21

> 前文的成本计算方式其实与MySQL 5.7.22 中的成本计算方式稍有不同，但是核心思路没变
>
> 不论是采用idx_keyl 还是uk_key2执行查询，它们对应的都是range 访问方法。在使用range 访问方法执行查询时，扫描区间中包含多少条记录，优化器就认为需要进行多少次回表操作，也就相当于需要进行多少次页面 I/O。不过对于ref访问方法来说，InnoDB 在计算因回表操作带来的 I/O 成本时设置了天花板，也就是 ref 访问方法因回表操作带来的 I/O 成本最多不能超过相当于访问全表记录数的 1/10 个页面的 I/O 成本或者全表扫描的 I/O 成本的 3 倍。

### 12.2.3 基于索引统计数据的成本计算

有时在使用索引执行查询时会有许多单点扫描区间， 使用 IN 语句就很容易产生非常多的单点扫描区间。

MySQL 把这种通过直接访问索引对应的 B+ 树来计算某个扫描区间内对应的索引记录条数的方式称为 index dive

> 也就是说，在查询真正执行前的执行计划生成阶段，就可能少量地访问B+ 树中的数据

系统变量 eq_range_index_dive_limit：如果通过 IN 语句生成的单点扫描区间的数量小于该系统值，将使用 index dive 来计算各个单点扫锚区间对应的记录条数；大于该值，就不能使用 index dive 了（以防 index dive 过多，计算扫描区间对应的索引记录条数的成本大过直接全表扫描）

```mysql
mysql> show variables like '%dive%';
+---------------------------+-------+
| Variable_name             | Value |
+---------------------------+-------+
| eq_range_index_dive_limit | 200   |
+---------------------------+-------+
1 row in set (0.01 sec)
```

大于 200 则：索引统计数据（index statistics）估算

MySQL 会为表中的每一个索引维护一份统计数据

```mysql
show index from 表名
```

```mysql
mysql> show index from single_table;
+--------------+------------+--------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
| Table        | Non_unique | Key_name     | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | Visible | Expression |
+--------------+------------+--------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
| single_table |          0 | PRIMARY      |            1 | id          | A         |           0 |     NULL |   NULL |      | BTREE      |         |               | YES     | NULL       |
| single_table |          0 | uk_key2      |            1 | key2        | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
| single_table |          1 | idx_key1     |            1 | key1        | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
| single_table |          1 | idx_key3     |            1 | key3        | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
| single_table |          1 | idx_key_part |            1 | key_part1   | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
| single_table |          1 | idx_key_part |            2 | key_part2   | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
| single_table |          1 | idx_key_part |            3 | key_part3   | A         |           0 |     NULL |   NULL | YES  | BTREE      |         |               | YES     | NULL       |
+--------------+------------+--------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+---------+------------+
```

SHOW INDEX 语句的输出结果中的一条记录就代表某个索引中的一个列。

每个列都有多个属性

| 属性名          | 描述                                                         |
| --------------- | ------------------------------------------------------------ |
| `Table`         | 该列所属索引所在的表的名称                                   |
| `Non_unique`    | 该列所属索引是否是唯一索引                                   |
| `Key_name`      | 该列所属索引的名称。如果是聚簇索引的话，Key_name 为 PRlAMRY  |
| `Seq_in_index`  | 该列在索引包含的列中的位置， 从 1 开始计数。比如对于联合索引 idx_key_part 来说，key_part1、key_part2 和 key_part3 对应的位置分别是1 、2、3 |
| `Column_name`   | 该列的名称                                                   |
| `Collation`     | 该列中的值是按照哪种排序方式存放的。Collation 为 A 时代表升序存放；Collation 为 NULL 代表不排序 |
| `Cardinality`   | 该列中不重复值的数量。对于联合索引来说，该值表示从索引列的第一个列开始，到本列为止的列组合不重复的数量。比如联合索引 idx_key_part，key_part2 列的 Cardinality 属性代表 key_part1、key_part2 的组合不重复的数量，key_part3 列的 Cardinality 属性代表 key_part1、key_part2、key_part3 的组合不重复的数量 |
| `Sub_part`      | 对于存储字符串或者字节串的列来说， 有时只想对这些串的前 n 个字符或字节建立索引，这个值表示的就是 n。如果对完整的列建立索引，Sub_part 的值就是 NULL |
| `Packed`        | 该列如何被压缩， NULL 值表示未被压缩                         |
| `Null`          | 该列是否允许存储NULL 值                                      |
| `Index_type`    | 该列所属索引的类型， 我们最常见的就是BTREE. 其实也就是B+ 树索引 |
| `Comment`       | 该列所属索引的一些额外信息                                   |
| `Index_comment` | 创建索引时，使用COMMENT 语句为该索引添加的注释信息           |

>  Cardinality 在中文中是" 基数"的意思， 表示某个列中不重复的值的个数。对于InnoDB 存储引擎来说，使用SHOW INDEX 语句显示出来的某个列的 Cardinality 属性是一个估计值，并不精确

索引统计数据指的是

+ 使用SHOW TABLE STATUS 语句显示出来的Rows 值
+ 使用SHOW INDEX 语句显示出来的 Cardinality 属性

结合Rows 统计数据，我们可以计算出在某一个列中一个值平均重复多少次. 一个值的重复次数大约等于Rows 除以Cardinality 的值

使用统计数据来计算单点扫描区间对应的索引记录条数比 index dive 方式简单多了，但是缺点是不精确！使用统计数据算出来的查询成本与实际执行时的成本可能相差很大

> 在 MySQL5.7.3 之前的版本，eq_range_index_dive_limit 的默认值是 10，之后的版本默认值是 200。
>
> 当查询中包含了 IN 子句，但是实际上并没有使用索引执行查询，应该考虑下是否因为 eq_range_index_dive_limit 的值太小而导致的

## 12.3 连接查询的成本

### 12.3.1 准备工作

构造一个和 single_table（s1） 一样的表 single_table2（s2）

### 12.3.2 条件过滤（Condition Filtering）

对于两表连接查询来说， 它的查询成本由两部分构成

+ 单次查询驱动表的成本
+ 多次查询被驱动表的成本

我们把查询驱动表后得到的记录条数称为驱动表的扇出（fanout）

驱动表的扇出值越小，对被驱表的查询次数也就越少，连接查询的总成本就越低

计算扇出值

+ ```mysql
  select * from s1 inner join s2;
  ```

  假设使用 s1 表作为驱动表，很显然就只能使用全表扫描的方式对驱动表执行单表查询。驱动表的扇出值也很明确，那就是驱动表中有多少记录，扇出值就是多少（show table status like 'single_table'\G;）

+ ```mysql
  select * from s1 inner join s2
  	where s1.key2 > 10 and s1.key2 < 1000;
  ```

  仍然假设sl 表是驱动衰，很显然可以使用uk_key2 索引对驱动表执行单表查询。此时 uk_key2的扫描区间( 10 ， 1000) 中有多少条记录， 那么扇出值就是多少（前面计算过是 95）

+ ```mysql
  select * from s1 inner join s2
  	where s1.common_field > 'xyz';
  ```

  和查询 l 类似，只不过在查询驱动表 s1 时多了一个 common_field > 'xyz' 的搜索条件。优化器又不会真正地去执行查询，所以它只能猜这 9693 条记录中有多少条记录满足 common_field > 'xyz'

+ ```mysql
  select * from s1 inner join s2
  	where s1.key2 > 10 and s1.key2 < 1000 and
  				s1.key1 in ('a', 'b', 'c') and
  				s1.common_field > 'xyz';
  ```

  和查询2 类似，不过在对驱动表s l 选取uk_key2 索引执行查询后， 查询优化器需要在二级索引扫描区间的记录中猜测有多少条记录符合下面两个条件

  + key1 in ('a', 'b', 'c')
  + common_field > 'xyz'

达在下面两种情况下计算驱动表扇出值时， 需要靠猜测

+ 如果使用全表扫描的方式执行单表查询，那么计算驱动表扇出值时需要猜测满足全部搜索条件的记录到底有多少条
+ 如果使用索引来执行单表查询，那么计算驱动表扇出值时需要猜测除了满足形成索引扫描区间的搜索条件外，还满足其他搜索条件的记录有多少条

MySQL 称这个猜测的过程为 Condition Filtering（条件过滤）

这个猜测过程可能会使用到索引，也可能会使用到统计数据，也有可能单纯瞎猜

### 12.3.3 两表连接的成本分析

连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出值 × 单次访问被驱动表的成本

对于左( 外)连接和右(外〕连接查询来说， 它们的驱动表是固定的，所以只需要分别为驱动表和被驱动表选择成本最低的访问方法，就可以得到最优的查询方案

对于内连接来说，驱动表和被驱动表的位置是可以互换的，因此需要考虑两个方面的问题

+ 当不同的表作为驱动表时， 最终的查询成本可能不同，也就是需要考虑最优的表连接顺序;
+ 然后分别为驱动表和被驱动表选择成本最低的访问方法

> 左(外)连接和右〈外)连接查询在某些特殊情况下可以被优化为内连接查询

```mysql
select * from s1 inner join s2
	on s1.key1 = s2.common_field
	where s1.key2 > 10 and s1.key2 < 1000 and
				s2.key2 > 1000 and s2.key2 < 2000;
```

#### 1. s1 作驱动表

#### 2. s2 作驱动表

> 优化重点就是：尽量减少驱动表扇出；访问被驱动表的成本尽量低

### 12.3.4 多表连接的成于分析

对于n 表连接，就是n 的阶乘种连接顺序

MySQL 想了很多办法减少因计算不同连接顺序下的查询成本而带来的性能损耗

+ 提前结束某种连接顺序的成本评估

+ 系统变量。optimizer_search_depth

+ 某些规则不考虑某些连接顺序

  optimizer_prune_level

## 12.4 调节成本常数

```mysql
mysql> show tables from mysql like '%cost%';
+--------------------------+
| Tables_in_mysql (%cost%) |
+--------------------------+
| engine_cost              |
| server_cost              |
+--------------------------+
2 rows in set (0.01 sec)
```

那些在se凹er 层进行的操作对应的成本常数存储在 server_cost 表中

依赖于存储引擎的操作对应的成本常数存储在 engine_cost 表中

### 12.4.1 mysql.server_cost 表

```mysql
mysql> select * from mysql.server_cost;
+------------------------------+------------+---------------------+---------+---------------+
| cost_name                    | cost_value | last_update         | comment | default_value |
+------------------------------+------------+---------------------+---------+---------------+
| disk_temptable_create_cost   |       NULL | 2020-06-05 17:16:48 | NULL    |            20 |
| disk_temptable_row_cost      |       NULL | 2020-06-05 17:16:48 | NULL    |           0.5 |
| key_compare_cost             |       NULL | 2020-06-05 17:16:48 | NULL    |          0.05 |
| memory_temptable_create_cost |       NULL | 2020-06-05 17:16:48 | NULL    |             1 |
| memory_temptable_row_cost    |       NULL | 2020-06-05 17:16:48 | NULL    |           0.1 |
| row_evaluate_cost            |       NULL | 2020-06-05 17:16:48 | NULL    |           0.1 |
+------------------------------+------------+---------------------+---------+---------------+
6 rows in set (0.00 sec)
```

+ cost_value：表示成本常数对应的值。如果该列的值为NULL.则意味着对应的成本常数会采用默认值.

| 成本常数名称                   | 默认值 | 描述                                                         |
| ------------------------------ | ------ | ------------------------------------------------------------ |
| `disk_temptable_create_cost`   | 40.0   | 创建基于磁盘的临时袤的成本.如果增大这个值，则会让查询优化器尽可能少地创建基于磁盘的临时表 |
| `disk_temptable_row_cost`      | 1.0    | 向基于磁盘的临时我写入或读取一条记录的成本.如果增大这个值，则会让查询优化精尽可能少地创建基于磁盘的临时表 |
| `key_compare_cost`             | 0.1    | 两条记录进行比较操作的成本，多用在排序操作中.如果增大这个值， 则会提升 filesort 的成本，从而让查询优化器更倾向于使用索引〈而不是 filesort） 完成排序 |
| `memory_temptable_create_cost` | 2.0    | 创建基于内存的临时表的戚本.如果增大这个值，则会让查询优化器尽可能少地创建基于内存的临时表 |
| `memory_temptable_row_cost`    | 0.2    | 向基于内存的临时装写入或读取一条记录的成本.如果增大这个值，则会让查询优化精尽可能少地创建基于内存的临时表 |
| `row_evaluate_cost`            | 0.2    | 读取并检测一条记录是否符合搜索条件的成本（我们在前面一直使用的就是它）。如果增大这个值，可能会让查询优化器更倾向于使用索引〈而不是全表扫描〉 |

> 创建临时束以及对这个临时表进行写入和读取的操作代价还是很高的

**修改**

```mysql
update mysql.server_cost
	set cost_value = 0.4
	where cost_name = 'row_evaluate_cost';
	
flush optimizer_costs;
```

### 12.4.2 mysql.engine_cost 表

记录了在存储引擎层进行的一些操作所对应的成本常数

```mysql
mysql> select * from mysql.engine_cost;
+-------------+-------------+------------------------+------------+---------------------+---------+---------------+
| engine_name | device_type | cost_name              | cost_value | last_update         | comment | default_value |
+-------------+-------------+------------------------+------------+---------------------+---------+---------------+
| default     |           0 | io_block_read_cost     |       NULL | 2020-06-05 17:16:48 | NULL    |             1 |
| default     |           0 | memory_block_read_cost |       NULL | 2020-06-05 17:16:48 | NULL    |          0.25 |
+-------------+-------------+------------------------+------------+---------------------+---------+---------------+
2 rows in set (0.00 sec)
```

+ engine_name：成本常数适用的存储引擎的名称。default 说明适合所有
+ device_type：为了区分常规的机械硬盘和固态硬盘

| 成本常数名称             | 默认值 | 描述                                                         |
| ------------------------ | ------ | ------------------------------------------------------------ |
| `io_block_read_cost`     | 1.0    | 从磁盘上读取一个块对应的成本.请注意这里使用的是"块” 而不“页”。对于InnoDB 存储引擎来说，一个页就是一个块，不过对于MylSAM 存储引擎来说.默认以4096  字节作为一个块 |
| `memory_block_read_cost` | 0.25   | 衡量的是从内存中读取一个块对应的成本                         |

## 12.5 总结




------

[toc]